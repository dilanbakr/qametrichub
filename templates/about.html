{% extends "index.html" %}

{% block content %}
    <div class="card">
        <div class="card-header">
            <h5 class="card-title">QA Evaluation generate</h5>
            <h6 class="card-subtitle text-muted">Generate Score</h6>
        </div>
        <div class="card-body">
            <p class="text-justify">
                Traditional evaluation methods, which rely on superficial similarity measures, can't catch the complex accuracy and reasoning needed in legal answers. This means that evaluation methods need to change completely. To fix the problems with current methods, this study presents a new moddel-based evaluation metric that is designed to work well with legal QA systems. We are looking into the basic ideas that are needed for this kind of metric, as well as the problems of putting it into practice in the real world, finding the right technological frameworks, creating good evaluation methods. We talk about a theory framework that is based on legal standards and computational linguistics. We also talk about how the metric was created and how it can be used in real life. Our results, which come from thorough tests, show that our suggested measure is better than existing ones. It is more reliable, accurate, and useful for judging legal quality assurance systems.
            </p>
        </div>
    </div>
    </div>
    </div>
{% endblock %}

